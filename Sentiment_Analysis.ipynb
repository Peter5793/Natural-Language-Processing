{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdf4920",
   "metadata": {},
   "source": [
    "### Sentiment Analysis on Womens Clothing\n",
    "##### Predict sentiments on women's clothing, either as positive or negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6b71d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wordcloud in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a094ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import the neccesary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import nltk.corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ea38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ce4a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data\n",
    "data = \"D:/Data_work/Womens Clothing E-Commerce Reviews.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33bacf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Unnamed: 0\n",
      "[1] Clothing ID\n",
      "[2] Age\n",
      "[3] Title\n",
      "[4] Review Text\n",
      "[5] Rating\n",
      "[6] Recommended IND\n",
      "[7] Positive Feedback Count\n",
      "[8] Division Name\n",
      "[9] Department Name\n",
      "[10] Class Name\n"
     ]
    }
   ],
   "source": [
    "# read the number of columns and the index\n",
    "df.columns\n",
    "for index, i in enumerate(df.columns):\n",
    "    print([index],i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf97bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "Clothing ID                   0\n",
       "Age                           0\n",
       "Title                      3810\n",
       "Review Text                 845\n",
       "Rating                        0\n",
       "Recommended IND               0\n",
       "Positive Feedback Count       0\n",
       "Division Name                14\n",
       "Department Name              14\n",
       "Class Name                   14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in the data set\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94db95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb48e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           2         1077   60  Some major design flaws   \n",
       "1           3         1049   50         My favorite buy!   \n",
       "2           4          847   47         Flattering shirt   \n",
       "3           5         1080   49  Not for the very petite   \n",
       "4           6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  I had such high hopes for this dress and reall...       3                0   \n",
       "1  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "2  This shirt is very flattering to all due to th...       5                1   \n",
       "3  I love tracy reese dresses, but this one is no...       2                0   \n",
       "4  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0         General         Dresses    Dresses  \n",
       "1                        0  General Petite         Bottoms      Pants  \n",
       "2                        6         General            Tops    Blouses  \n",
       "3                        4         General         Dresses    Dresses  \n",
       "4                        1  General Petite            Tops      Knits  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index after dropping the NA values\n",
    "df.reset_index(drop=True, inplace =True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409ad238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                                        Review Text  \\\n",
       "0         1077   60  I had such high hopes for this dress and reall...   \n",
       "1         1049   50  I love, love, love this jumpsuit. it's fun, fl...   \n",
       "2          847   47  This shirt is very flattering to all due to th...   \n",
       "3         1080   49  I love tracy reese dresses, but this one is no...   \n",
       "4          858   39  I aded this in my basket at hte last mintue to...   \n",
       "\n",
       "   Rating  Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0       3                0                        0         General   \n",
       "1       5                1                        0  General Petite   \n",
       "2       5                1                        6         General   \n",
       "3       2                0                        4         General   \n",
       "4       5                1                        1  General Petite   \n",
       "\n",
       "  Department Name Class Name  \n",
       "0         Dresses    Dresses  \n",
       "1         Bottoms      Pants  \n",
       "2            Tops    Blouses  \n",
       "3         Dresses    Dresses  \n",
       "4            Tops      Knits  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the unncessary values in the dataset\n",
    "df.drop([\"Unnamed: 0\",\"Title\"], axis = 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5c92b",
   "metadata": {},
   "source": [
    "The useful columns for the Analysis will be Review Text and the Recommended IND to classify the review s negative and postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e381e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended_IND</th>\n",
       "      <th>Positive_Feedback_Count</th>\n",
       "      <th>Division_Name</th>\n",
       "      <th>Department_Name</th>\n",
       "      <th>Class_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing_ID  Age                                        Review_Text  \\\n",
       "0         1077   60  I had such high hopes for this dress and reall...   \n",
       "1         1049   50  I love, love, love this jumpsuit. it's fun, fl...   \n",
       "2          847   47  This shirt is very flattering to all due to th...   \n",
       "3         1080   49  I love tracy reese dresses, but this one is no...   \n",
       "4          858   39  I aded this in my basket at hte last mintue to...   \n",
       "\n",
       "   Rating  Recommended_IND  Positive_Feedback_Count   Division_Name  \\\n",
       "0       3                0                        0         General   \n",
       "1       5                1                        0  General Petite   \n",
       "2       5                1                        6         General   \n",
       "3       2                0                        4         General   \n",
       "4       5                1                        1  General Petite   \n",
       "\n",
       "  Department_Name Class_Name  \n",
       "0         Dresses    Dresses  \n",
       "1         Bottoms      Pants  \n",
       "2            Tops    Blouses  \n",
       "3         Dresses    Dresses  \n",
       "4            Tops      Knits  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove spaces in the column titles and replace them with \"_\"\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf6c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating review Tuples to store the words with the categories\n",
    "reviews = []\n",
    "# going through the recommeneded IND column and get the category\n",
    "# and index\n",
    "for (index, category) in enumerate(df.Recommended_IND):\n",
    "    reviews.append((df.Review_Text[index], category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a835cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c',\n",
       "  0),\n",
       " (\"I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\",\n",
       "  1),\n",
       " ('This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!',\n",
       "  1),\n",
       " ('I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.',\n",
       "  0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f9a9a",
   "metadata": {},
   "source": [
    "#### Cleaning the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1573e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lemmatizer object \n",
    "lemmatizer  = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa78f86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  '!',\n",
       "  '\"',\n",
       "  '#',\n",
       "  '$',\n",
       "  '%',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  '(',\n",
       "  ')',\n",
       "  '*',\n",
       "  '+',\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '/',\n",
       "  ':',\n",
       "  ';',\n",
       "  '<',\n",
       "  '=',\n",
       "  '>',\n",
       "  '?',\n",
       "  '@',\n",
       "  '[',\n",
       "  '\\\\',\n",
       "  ']',\n",
       "  '^',\n",
       "  '_',\n",
       "  '`',\n",
       "  '{',\n",
       "  '|',\n",
       "  '}',\n",
       "  '~'],\n",
       " '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of stopwards\n",
    "stops = stopwords.words(\"english\")\n",
    "punctuations = list(string.punctuation)\n",
    "stops = stops + punctuations\n",
    "stops, string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27d9682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " \"i'm\",\n",
       " 'would',\n",
       " 'look',\n",
       " 'ordered',\n",
       " 'wear',\n",
       " 'fit',\n",
       " 'one',\n",
       " 'fits',\n",
       " 'bought',\n",
       " 'looks',\n",
       " 'also',\n",
       " 'got',\n",
       " 'think',\n",
       " 'even',\n",
       " 'tried',\n",
       " 'get',\n",
       " 'could',\n",
       " 'made',\n",
       " 'way',\n",
       " 'still',\n",
       " 'runs',\n",
       " 'true',\n",
       " 'right',\n",
       " 'see',\n",
       " 'online',\n",
       " 'wearing',\n",
       " 'however',\n",
       " 'design',\n",
       " 'purchased',\n",
       " 'feel',\n",
       " 'go',\n",
       " 'enough',\n",
       " 'model',\n",
       " 'though',\n",
       " 'price',\n",
       " 'looked',\n",
       " 'person',\n",
       " 'better',\n",
       " 'first',\n",
       " 'going',\n",
       " 'try',\n",
       " 'bodybottom',\n",
       " 'time',\n",
       " 'many',\n",
       " 'looking',\n",
       " 'around',\n",
       " 'thought',\n",
       " 'make',\n",
       " 'wanted',\n",
       " 'saw',\n",
       " 'makes',\n",
       " 'went',\n",
       " 'find',\n",
       " 'found',\n",
       " 'buy',\n",
       " 'nan',\n",
       " \"i've\",\n",
       " 'since',\n",
       " 'seems',\n",
       " 'ok',\n",
       " 'girl',\n",
       " 'woman']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# busines stopwords\n",
    "business_stopwords= [\"i'm\",\"would\", \"look\", \"ordered\", \"wear\", \"fit\", \"one\", \"fits\",\"bought\", \"looks\", \"also\", \"got\", \"think\", \"even\",\n",
    "                     \"tried\", \"get\", \"could\", \"made\",\"way\",\"still\", \"runs\",\"true\" ,\"right\", \"see\",\"online\",\"wearing\", \"however\", \"design\",\"purchased\",\"feel\",\"go\",\n",
    "                     \"enough\",\"model\",\"though\",\"price\",\"looked\",\"person\",\"better\",\"first\",\"going\",\"try\", \"body\" \"bottom\",\"time\",\"many\",\"looking\",\"around\",\"thought\",\n",
    "                     \"make\",\"wanted\",\"saw\",\"makes\",\"went\",\"find\",\"found\",\"buy\",\"nan\",\"i've\", \"since\",\"seems\",\"ok\", \"girl\", \"woman\"]\n",
    "stops = stops + business_stopwords\n",
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040161f",
   "metadata": {},
   "source": [
    "## Lemmatization of the text\n",
    "Writing a function to lemmatize the words and clean them using the stop word list created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0592f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words after updated with business_stopwords\n",
    "len(stops)\n",
    "# parts of speech tagging  to use in the lemmitization\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('N') or tag.startswith('J'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99aebd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words =[]\n",
    "    words_tokens = nltk.word_tokenize(words)\n",
    "    for word in words_tokens:\n",
    "        if word.lower() not in stops:\n",
    "            pos = pos_tag([word]) # get the part of speech\n",
    "            \n",
    "            clean_word = (lemmatizer.lemmatize(word.lower(),\n",
    "                                              pos = get_simple_pos(tag)) for word, tag in pos)\n",
    "            output_words.append(', '.join(map(str,clean_word)))\n",
    "    return output_words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcf1dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'run', 'away', 'arm']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function\n",
    "\n",
    "clean_review(\"My cats are running away from my arms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f64ce819",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review = [(clean_review(text), category) for text, category in reviews\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1520e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19662"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e08527c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['high',\n",
       "   'hope',\n",
       "   'dress',\n",
       "   'really',\n",
       "   'work',\n",
       "   'initially',\n",
       "   'petite',\n",
       "   'small',\n",
       "   'usual',\n",
       "   'size',\n",
       "   'outrageously',\n",
       "   'small',\n",
       "   'small',\n",
       "   'fact',\n",
       "   'zip',\n",
       "   'reorder',\n",
       "   'petite',\n",
       "   'medium',\n",
       "   'ok.',\n",
       "   'overall',\n",
       "   'top',\n",
       "   'half',\n",
       "   'comfortable',\n",
       "   'nicely',\n",
       "   'bottom',\n",
       "   'half',\n",
       "   'tight',\n",
       "   'layer',\n",
       "   'several',\n",
       "   'somewhat',\n",
       "   'cheap',\n",
       "   'net',\n",
       "   'layer',\n",
       "   'imo',\n",
       "   'major',\n",
       "   'flaw',\n",
       "   'net',\n",
       "   'layer',\n",
       "   'sewn',\n",
       "   'directly',\n",
       "   'zipper',\n",
       "   'c'],\n",
       "  0),\n",
       " (['love',\n",
       "   'love',\n",
       "   'love',\n",
       "   'jumpsuit',\n",
       "   \"'s\",\n",
       "   'fun',\n",
       "   'flirty',\n",
       "   'fabulous',\n",
       "   'every',\n",
       "   'nothing',\n",
       "   'great',\n",
       "   'compliment'],\n",
       "  1),\n",
       " (['shirt',\n",
       "   'flatter',\n",
       "   'due',\n",
       "   'adjustable',\n",
       "   'front',\n",
       "   'tie',\n",
       "   'perfect',\n",
       "   'length',\n",
       "   'legging',\n",
       "   'sleeveless',\n",
       "   'pair',\n",
       "   'well',\n",
       "   'cardigan',\n",
       "   'love',\n",
       "   'shirt'],\n",
       "  1),\n",
       " (['love',\n",
       "   'tracy',\n",
       "   'reese',\n",
       "   'dress',\n",
       "   'petite',\n",
       "   '5',\n",
       "   'foot',\n",
       "   'tall',\n",
       "   'usually',\n",
       "   '0p',\n",
       "   'brand',\n",
       "   'dress',\n",
       "   'pretty',\n",
       "   'package',\n",
       "   'lot',\n",
       "   'dress',\n",
       "   'skirt',\n",
       "   'long',\n",
       "   'full',\n",
       "   'overwhelmed',\n",
       "   'small',\n",
       "   'frame',\n",
       "   'stranger',\n",
       "   'alteration',\n",
       "   'shorten',\n",
       "   'narrow',\n",
       "   'skirt',\n",
       "   'take',\n",
       "   'away',\n",
       "   'embellishment',\n",
       "   'garment',\n",
       "   'love',\n",
       "   'color',\n",
       "   'idea',\n",
       "   'style',\n",
       "   'work',\n",
       "   'return',\n",
       "   'dress'],\n",
       "  0),\n",
       " (['aded',\n",
       "   'basket',\n",
       "   'hte',\n",
       "   'last',\n",
       "   'mintue',\n",
       "   'like',\n",
       "   'store',\n",
       "   'pick',\n",
       "   'teh',\n",
       "   'darkler',\n",
       "   'color',\n",
       "   'pale',\n",
       "   'hte',\n",
       "   'color',\n",
       "   'really',\n",
       "   'gorgeous',\n",
       "   'turn',\n",
       "   'mathced',\n",
       "   'everythiing',\n",
       "   'try',\n",
       "   'prefectly',\n",
       "   'little',\n",
       "   'baggy',\n",
       "   'hte',\n",
       "   'x',\n",
       "   'hte',\n",
       "   'msallet',\n",
       "   'size',\n",
       "   'bummer',\n",
       "   'petite',\n",
       "   'decide',\n",
       "   'jkeep',\n",
       "   'say',\n",
       "   'matvehd',\n",
       "   'everything',\n",
       "   'ejans',\n",
       "   'pant',\n",
       "   '3',\n",
       "   'skirt',\n",
       "   'waas',\n",
       "   'try',\n",
       "   'kept',\n",
       "   'oops'],\n",
       "  1),\n",
       " (['carbon',\n",
       "   'store',\n",
       "   'pick',\n",
       "   'ton',\n",
       "   'stuff',\n",
       "   'always',\n",
       "   'use',\n",
       "   'top',\n",
       "   'pair',\n",
       "   'skirt',\n",
       "   'pant',\n",
       "   'everything',\n",
       "   'color',\n",
       "   'really',\n",
       "   'nice',\n",
       "   'charcoal',\n",
       "   'shimmer',\n",
       "   'well',\n",
       "   'pencil',\n",
       "   'skirt',\n",
       "   'flare',\n",
       "   'pant',\n",
       "   'etc',\n",
       "   'compaint',\n",
       "   'bit',\n",
       "   'big',\n",
       "   'sleeve',\n",
       "   'long',\n",
       "   \"n't\",\n",
       "   'petite',\n",
       "   'bit',\n",
       "   'loose',\n",
       "   'xx',\n",
       "   '...',\n",
       "   'kept',\n",
       "   'wil',\n",
       "   'ldecide',\n",
       "   'later',\n",
       "   'light',\n",
       "   'color',\n",
       "   'already',\n",
       "   'sell',\n",
       "   'hte',\n",
       "   'smallest',\n",
       "   'size',\n",
       "   '...'],\n",
       "  1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the first 5 reviews\n",
    "cleaned_review[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d7918",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "* 75% for training\n",
    "* 25% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f77292ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig data = 14746\n",
      "Testing data = 4916\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainig data = {}\".format(round(0.75*len(cleaned_review))))\n",
    "print(\"Testing data = {}\".format(round(0.25*len(cleaned_review))))\n",
    "\n",
    "training_data = cleaned_review[0:14746]\n",
    "testing_data = cleaned_review[14746: 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53d3c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array containing all of the days\n",
    "word_list = []\n",
    "for word in training_data:\n",
    "    word_list+=word[0] # 0 index to get only the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2377528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392719"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e22a5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distribution for all words\n",
    "freq = nltk.FreqDist(word_list)\n",
    "# most .most_common() method lists the words which occur most frequently\n",
    "# in the data\n",
    "common = freq.most_common()\n",
    "# features are an array of only the top words in word \n",
    "#list without The number of words\n",
    "features = [i[0] for i in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19b5d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12805\n",
      "12805\n"
     ]
    }
   ],
   "source": [
    "print(len(common))\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab4a57a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dress', 8091), ('size', 7083), ('love', 6701), (\"n't\", 5543), ('top', 5450)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common 5 words\n",
    "common[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e44ba857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dress', 'size', 'love', \"n't\", 'top']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc596772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d1a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
